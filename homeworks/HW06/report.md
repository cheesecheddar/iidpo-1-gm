# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12 000 строк, 30 столбцов)
- Целевая переменная: `target` – бинарная классификация (0/1)
  - Класс 0: ~67.7% (умеренный дисбаланс)
  - Класс 1: ~32.3%
- Признаки:
  - 24 числовых признака (`num01` – `num24`): непрерывные значения, разные масштабы
  - 3 категориальных-подобных (`cat_contract`, `cat_region`, `cat_payment`): целые значения 0-4
  - 1 числовой признак `tenure_months`: месяцы владения продуктом (3-106)
  - Пропусков нет

## 2. Protocol

- Разбиение: train/test = 75% / 25% (`test_size=0.25`, `random_state=42`, `stratify=y`)
  
- Подбор: 5 фолдов cross-validation
  - Оптимизация по метрике: ROC-AUC
  - GridSearchCV для DecisionTree, RandomForest, GradientBoosting
  - Test set использован один раз для финальной оценки (честный эксперимент)

- Метрики:
  - accuracy – общая доля верных предсказаний (информативна при умеренном дисбалансе)
  - F1 – гармоническое среднее precision и recall (важно для minority class)
  - ROC-AUC – основная метрика для ранжирования (устойчива к порогу классификации)
  
  Эти метрики уместны для бинарной классификации с умеренным дисбалансом, где важно не только общее качество, но и способность модели различать классы.

## 3. Models

Сравнил 5 моделей, из которых 2 baseline'а и 3 модели недели 6:

1. DummyClassifier (`strategy="most_frequent"`)
   - Простейший baseline, всегда предсказывает majority class
   - Параметры: `random_state=42`

2. LogisticRegression (Pipeline: StandardScaler + LogisticRegression)
   - Линейная модель с нормализацией признаков
   - Параметры: `max_iter=1000`, `random_state=42`

3. DecisionTreeClassifier (контроль сложности)
   - Подбор параметров: `max_depth` = {3, 5, 7, 10}, `min_samples_leaf` = {1, 2, 5, 10}
   - Лучшие параметры: `max_depth=10`, `min_samples_leaf=10`

4. RandomForestClassifier (bagging + случайность по признакам)
   - Подбор параметров: `n_estimators` = {50, 100, 200}, `max_depth` = {5, 10, None}, `min_samples_leaf` = {1, 2, 4}
   - Лучшие параметры: `n_estimators=200`, `max_depth=None`, `min_samples_leaf=2`

5. GradientBoostingClassifier (boosting)
   - Подбор параметров: `n_estimators` = {50, 100, 150}, `learning_rate` = {0.01, 0.05, 0.1}, `max_depth` = {3, 5, 7}
   - Лучшие параметры: `n_estimators=150`, `learning_rate=0.1`, `max_depth=7`, `subsample=0.8`

## 4. Results

Таблица финальных метрик на test set:

| Модель              | Accuracy | F1-score | ROC-AUC  |
|---------------------|----------|----------|----------|
| DummyClassifier     | 0.6767   | 0.0000   | 0.5000   |
| LogisticRegression  | 0.8297   | 0.7147   | 0.8789   |
| DecisionTree        | 0.8780   | 0.8036   | 0.9165   |
| RandomForest        | 0.9323   | 0.8900   | 0.9698   |
| GradientBoosting    | 0.9353   | 0.8961   | 0.9746   |

Победитель: GradientBoostingClassifier
Критерий выбора: ROC-AUC = 0.9746 (лучший результат)
- Gradient Boosting последовательно исправляет ошибки предыдущих деревьев, что позволяет лучше улавливать сложные закономерности в данных
- Превосходит RandomForest по всем метрикам (хотя разница небольшая: +0.0048 по AUC)
- CV-score (0.9716) близок к test-score (0.9746), что говорит об отсутствии переобучения
- Значительно превосходит baseline'ы: +0.0957 по AUC над LogisticRegression

## 5. Analysis

- Устойчивость: эксперимент проведен с фиксированным `random_state=42` для  воспроизводимости. При одном seed результаты стабильны. Для проверки устойчивости к различным разбиениям данных рекомендуется провести 5-10 прогонов с разными seed'ами и проанализировать разброс метрик (не реализовано в текущей версии).

- Ошибки (Confusion Matrix для GradientBoosting):
 [[1952,   78]
 [  116,  854]]

 - 1952: модель правильно определила 96.2% отрицательных примеров
 - 78: 3.8% ложных срабатываний (класс 0 предсказан как 1)
 - 116: 12.0% пропущенных положительных случаев (класс 1 предсказан как 0)
 - 854: модель правильно определила 88.0% положительных примеров

 Модель показывает сбалансированное качество: хорошо работает на обоих классах, хотя чуть больше ошибается на minority class (что типично для дисбаланса).

- Интерпретация:

 Top-10 важных признаков для GradientBoosting:

 1. num19 (0.1157) – наиболее влиятельный признак
 2. num18 (0.1034) – второй по важности
 3. num13 (0.0680)
 4. num16 (0.0440)
 5. num03 (0.0277)
 6. num07 (0.0217)
 7. num12 (0.0210)
 8. num04 (0.0163)
 9. num06 (0.0153)
 10. num17 (0.0147)

 - Два признака (`num19`, `num18`) доминируют по важности, объясняя ~22% качества модели
 - Большинство топовых признаков – числовые (`num*`), что ожидаемо для деревьев решений
 - Категориальные признаки (`cat_*`) не попали в top-10, что может указывать на их меньшую предсказательную силу
 - Разброс важности постепенно снижается: модель использует много признаков, а не полагается только на 1-2

## 6. Conclusion

Основные выводы:

1. Ансамбли превосходят одиночные деревья: RandomForest и GradientBoosting показали ROC-AUC 0.97+, тогда как одиночное дерево – 0.92. Bagging и boosting эффективно снижают variance и улучшают обобщающую способность.

2. Контроль сложности критичен: DecisionTree с ограничением `max_depth=10` и `min_samples_leaf=10` показал разумный результат без переобучения. Без ограничений дерево легко запоминает шум.

3. Честный ML-протокол работает: Подбор гиперпараметров только на train через CV, test использован один раз. Близость CV-score и test-score (0.9716 vs 0.9746) подтверждает корректность процедуры.

4. Важность стратификации: При дисбалансе классов 68%/32% stratified split гарантирует репрезентативность train и test, что критично для надежных метрик.

5. ROC-AUC как основная метрика: В задачах с дисбалансом ROC-AUC лучше accuracy, т.к. учитывает способность модели ранжировать объекты, а не только итоговый порог классификации.

6. Gradient Boosting – мощный, но медленный: Лучший результат, но обучение занимает больше времени, чем все модели вместе взятые (3 минуты заняло выполнение блока).