{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed8b4a3",
   "metadata": {},
   "source": [
    "#### 2.3.1. Загрузка данных и первичный анализ (для каждого датасета)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23926a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Выбранные датасеты (3 из 4)\n",
    "datasets = [\n",
    "    (\"S07-hw-dataset-01.csv\"),\n",
    "    (\"S07-hw-dataset-02.csv\"),\n",
    "    (\"S07-hw-dataset-03.csv\")\n",
    "]\n",
    "\n",
    "# Словари для сохранения результатов\n",
    "metrics_summary = {}\n",
    "best_configs = {}\n",
    "dataset_labels = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc356b",
   "metadata": {},
   "source": [
    "#### 2.3.2. Препроцессинг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dedec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для препроцессинга\n",
    "def preprocess_dataset(X):\n",
    "    # Обработка пропусков\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    # Масштабирование\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    \n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff12f22",
   "metadata": {},
   "source": [
    "#### 2.3.1. - 2.3.4 загрузка, EDA, препроцессинг, обучение моделей KMeans и DBSCAN, прогон по метрикам\n",
    "Решил сделать так, чтобы не было 3 одинаковых блока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6544eb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET 1: S07-hw-dataset-01.csv\n",
      "\n",
      "Shape: (12000, 9)\n",
      "\n",
      "First rows:\n",
      "   sample_id        f01        f02       f03         f04        f05  \\\n",
      "0          0  -0.536647 -69.812900 -0.002657   71.743147 -11.396498   \n",
      "1          1  15.230731  52.727216 -1.273634 -104.123302  11.589643   \n",
      "2          2  18.542693  77.317150 -1.321686 -111.946636  10.254346   \n",
      "3          3 -12.538905 -41.709458  0.146474   16.322124   1.391137   \n",
      "4          4  -6.903056  61.833444 -0.022466  -42.631335   3.107154   \n",
      "\n",
      "         f06        f07       f08  \n",
      "0 -12.291287  -6.836847 -0.504094  \n",
      "1  34.316967 -49.468873  0.390356  \n",
      "2  25.892951  44.595250  0.325893  \n",
      "3   2.014316 -39.930582  0.139297  \n",
      "4  -5.471054   7.001149  0.131213  \n",
      "\n",
      "Descriptive stats:\n",
      "         sample_id           f01           f02           f03           f04  \\\n",
      "count  12000.00000  12000.000000  12000.000000  12000.000000  12000.000000   \n",
      "mean    5999.50000     -2.424716     19.107804     -0.222063     -8.284501   \n",
      "std     3464.24595     11.014315     60.790338      0.500630     59.269838   \n",
      "min        0.00000    -19.912573    -92.892652     -1.590979   -134.303679   \n",
      "25%     2999.75000     -9.472623    -40.282955     -0.125145    -48.345007   \n",
      "50%     5999.50000     -6.869404     54.069335     -0.031753     16.211728   \n",
      "75%     8999.25000      0.523841     70.280739      0.054980     28.067178   \n",
      "max    11999.00000     24.403381    112.229523      0.512277     75.088604   \n",
      "\n",
      "                f05           f06           f07           f08  \n",
      "count  12000.000000  12000.000000  12000.000000  12000.000000  \n",
      "mean      -0.190717      0.962972      0.033724      0.007638  \n",
      "std        7.026435     14.794713     59.541782      0.607053  \n",
      "min      -11.869169    -20.521164   -215.098834     -2.633469  \n",
      "25%       -5.132473     -8.807706    -39.900520     -0.401483  \n",
      "50%        0.444730     -6.134169     -0.578494      0.005306  \n",
      "75%        3.942368      2.334426     39.719821      0.410132  \n",
      "max       13.717091     41.452857    213.381767      2.490745  \n",
      "\n",
      "Missing values:\n",
      "sample_id    0\n",
      "f01          0\n",
      "f02          0\n",
      "f03          0\n",
      "f04          0\n",
      "f05          0\n",
      "f06          0\n",
      "f07          0\n",
      "f08          0\n",
      "dtype: int64\n",
      "Missing ratio:\n",
      "sample_id    0.0\n",
      "f01          0.0\n",
      "f02          0.0\n",
      "f03          0.0\n",
      "f04          0.0\n",
      "f05          0.0\n",
      "f06          0.0\n",
      "f07          0.0\n",
      "f08          0.0\n",
      "dtype: float64%\n",
      "\n",
      "Features shape: (12000, 8)\n",
      "Feature names: ['f01', 'f02', 'f03', 'f04', 'f05', 'f06', 'f07', 'f08']\n",
      "After scaling: mean=0.0000, std=1.0000\n",
      "\n",
      "1 KMeans - подбор k:\n",
      "  k=2: silhouette=0.5216\n",
      "  k=3: silhouette=0.3968\n",
      "  k=4: silhouette=0.3833\n",
      "  k=5: silhouette=0.3548\n",
      "  k=6: silhouette=0.3586\n",
      "  k=7: silhouette=0.3246\n",
      "  k=8: silhouette=0.2689\n",
      "  k=9: silhouette=0.2534\n",
      "  k=10: silhouette=0.2629\n",
      "Best k: 2 (silhouette=0.5216)\n",
      "KMeans metrics (k=2):\n",
      "  Silhouette: 0.5216\n",
      "  Davies-Bouldin: 0.6853\n",
      "  Calinski-Harabasz: 11786.9546\n",
      "\n",
      "2 DBSCAN - подбор параметров:\n",
      "  Best DBSCAN (eps=1.0, min_samples=10):\n",
      "  Silhouette: 0.3837\n",
      "  Davies-Bouldin: 1.1589\n",
      "  Calinski-Harabasz: 9460.9420\n",
      "  n_clusters: 4, noise_ratio: 0.0007\n",
      "\n",
      "Выбор лучшей модели:\n",
      "  Best: KMeans (k=2)\n",
      "DATASET 2: S07-hw-dataset-02.csv\n",
      "\n",
      "Shape: (8000, 4)\n",
      "\n",
      "First rows:\n",
      "   sample_id        x1        x2    z_noise\n",
      "0          0  0.098849 -1.846034  21.288122\n",
      "1          1 -1.024516  1.829616   6.072952\n",
      "2          2 -1.094178 -0.158545 -18.938342\n",
      "3          3 -1.612808 -1.565844 -11.629462\n",
      "4          4  1.659901 -2.133292   1.895472\n",
      "\n",
      "Descriptive stats:\n",
      "        sample_id           x1           x2      z_noise\n",
      "count  8000.00000  8000.000000  8000.000000  8000.000000\n",
      "mean   3999.50000     0.478867     0.241112     0.110454\n",
      "std    2309.54541     0.955138     0.663195     8.097716\n",
      "min       0.00000    -2.487352    -2.499237   -34.056074\n",
      "25%    1999.75000    -0.116516    -0.242357    -5.392210\n",
      "50%    3999.50000     0.490658     0.241092     0.132470\n",
      "75%    5999.25000     1.085263     0.726526     5.655605\n",
      "max    7999.00000     2.987555     2.995553    29.460076\n",
      "\n",
      "Missing values:\n",
      "sample_id    0\n",
      "x1           0\n",
      "x2           0\n",
      "z_noise      0\n",
      "dtype: int64\n",
      "Missing ratio:\n",
      "sample_id    0.0\n",
      "x1           0.0\n",
      "x2           0.0\n",
      "z_noise      0.0\n",
      "dtype: float64%\n",
      "\n",
      "Features shape: (8000, 3)\n",
      "Feature names: ['x1', 'x2', 'z_noise']\n",
      "After scaling: mean=0.0000, std=1.0000\n",
      "\n",
      "1 KMeans - подбор k:\n",
      "  k=2: silhouette=0.3069\n",
      "  k=3: silhouette=0.2700\n",
      "  k=4: silhouette=0.2515\n",
      "  k=5: silhouette=0.2521\n",
      "  k=6: silhouette=0.2598\n",
      "  k=7: silhouette=0.2536\n",
      "  k=8: silhouette=0.2523\n",
      "  k=9: silhouette=0.2525\n",
      "  k=10: silhouette=0.2609\n",
      "Best k: 2 (silhouette=0.3069)\n",
      "KMeans metrics (k=2):\n",
      "  Silhouette: 0.3069\n",
      "  Davies-Bouldin: 1.3235\n",
      "  Calinski-Harabasz: 3573.3933\n",
      "\n",
      "2 DBSCAN - подбор параметров:\n",
      "  Best DBSCAN (eps=0.7, min_samples=3):\n",
      "  Silhouette: 0.3455\n",
      "  Davies-Bouldin: 0.5510\n",
      "  Calinski-Harabasz: 10.4058\n",
      "  n_clusters: 2, noise_ratio: 0.0071\n",
      "\n",
      "Выбор лучшей модели:\n",
      "  Best: DBSCAN\n",
      "DATASET 3: S07-hw-dataset-03.csv\n",
      "\n",
      "Shape: (15000, 5)\n",
      "\n",
      "First rows:\n",
      "   sample_id        x1        x2    f_corr   f_noise\n",
      "0          0 -2.710470  4.997107 -1.015703  0.718508\n",
      "1          1  8.730238 -8.787416  3.953063 -1.105349\n",
      "2          2 -1.079600 -2.558708  0.976628 -3.605776\n",
      "3          3  6.854042  1.560181  1.760614 -1.230946\n",
      "4          4  9.963812 -8.869921  2.966583  0.915899\n",
      "\n",
      "Descriptive stats:\n",
      "          sample_id            x1            x2        f_corr       f_noise\n",
      "count  15000.000000  15000.000000  15000.000000  15000.000000  15000.000000\n",
      "mean    7499.500000      1.246296      1.033764      0.212776     -0.027067\n",
      "std     4330.271354      4.592421      4.710791      1.530017      2.506375\n",
      "min        0.000000     -9.995585     -9.980853     -5.212038     -8.785884\n",
      "25%     3749.750000     -1.782144     -2.666393     -0.966224     -1.731128\n",
      "50%     7499.500000      0.664226      1.831257      0.296508     -0.052391\n",
      "75%    11249.250000      4.435671      4.969630      1.390273      1.673831\n",
      "max    14999.000000     16.207863     14.271153      5.795876     11.266865\n",
      "\n",
      "Missing values:\n",
      "sample_id    0\n",
      "x1           0\n",
      "x2           0\n",
      "f_corr       0\n",
      "f_noise      0\n",
      "dtype: int64\n",
      "Missing ratio:\n",
      "sample_id    0.0\n",
      "x1           0.0\n",
      "x2           0.0\n",
      "f_corr       0.0\n",
      "f_noise      0.0\n",
      "dtype: float64%\n",
      "\n",
      "Features shape: (15000, 4)\n",
      "Feature names: ['x1', 'x2', 'f_corr', 'f_noise']\n",
      "After scaling: mean=-0.0000, std=1.0000\n",
      "\n",
      "1 KMeans - подбор k:\n",
      "  k=2: silhouette=0.2989\n",
      "  k=3: silhouette=0.3155\n",
      "  k=4: silhouette=0.3146\n",
      "  k=5: silhouette=0.2993\n",
      "  k=6: silhouette=0.2931\n",
      "  k=7: silhouette=0.2799\n",
      "  k=8: silhouette=0.2895\n",
      "  k=9: silhouette=0.2848\n",
      "  k=10: silhouette=0.2789\n",
      "Best k: 3 (silhouette=0.3155)\n",
      "KMeans metrics (k=3):\n",
      "  Silhouette: 0.3155\n",
      "  Davies-Bouldin: 1.1577\n",
      "  Calinski-Harabasz: 6957.1626\n",
      "\n",
      "2 DBSCAN - подбор параметров:\n",
      "  Best DBSCAN (eps=0.7, min_samples=3):\n",
      "  Silhouette: 0.2315\n",
      "  Davies-Bouldin: 0.5967\n",
      "  Calinski-Harabasz: 12.8622\n",
      "  n_clusters: 3, noise_ratio: 0.0029\n",
      "\n",
      "Выбор лучшей модели:\n",
      "  Best: KMeans (k=3)\n"
     ]
    }
   ],
   "source": [
    "for ds_idx, filename in enumerate(datasets, 1):\n",
    "    print(f\"DATASET {ds_idx}: {filename}\")\n",
    "    \n",
    "    # 2.3.1. загрузка и EDA\n",
    "    df = pd.read_csv(f'data/{filename}')\n",
    "    print(f\"\\nShape: {df.shape}\")\n",
    "    print(f\"\\nFirst rows:\\n{df.head()}\")\n",
    "    print(f\"\\nDescriptive stats:\\n{df.describe()}\")\n",
    "    \n",
    "    # Пропуски\n",
    "    print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Missing ratio:\\n{df.isnull().sum() / len(df) * 100}%\")\n",
    "    \n",
    "    # Извлекаем признаки (исключая sample_id)\n",
    "    sample_id = df['sample_id'].values\n",
    "    X = df.drop(columns=['sample_id']).values\n",
    "    \n",
    "    print(f\"\\nFeatures shape: {X.shape}\")\n",
    "    print(f\"Feature names: {df.drop(columns=['sample_id']).columns.tolist()}\")\n",
    "    \n",
    "    # 2.3.2. препроцессинг\n",
    "    X_scaled = preprocess_dataset(X)\n",
    "    print(f\"After scaling: mean={X_scaled.mean():.4f}, std={X_scaled.std():.4f}\")\n",
    "    \n",
    "    # 2.3.3. модели кластеризации\n",
    "    \n",
    "    # Словарь для метрик датасета\n",
    "    ds_metrics = {}\n",
    "    \n",
    "    # KMeans: подбор k \n",
    "    print(f\"\\n1 KMeans - подбор k:\")\n",
    "    k_values = range(2, 11)\n",
    "    kmeans_silhouette = []\n",
    "    kmeans_models = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = km.fit_predict(X_scaled)\n",
    "        sil = silhouette_score(X_scaled, labels)\n",
    "        kmeans_silhouette.append(sil)\n",
    "        kmeans_models[k] = (km, labels)\n",
    "        print(f\"  k={k}: silhouette={sil:.4f}\")\n",
    "    \n",
    "    # Выбираем лучший k по silhouette\n",
    "    best_k = k_values[np.argmax(kmeans_silhouette)]\n",
    "    km_best, km_labels = kmeans_models[best_k]\n",
    "    \n",
    "    print(f\"Best k: {best_k} (silhouette={max(kmeans_silhouette):.4f})\")\n",
    "    \n",
    "    # Метрики для лучшего KMeans\n",
    "    km_sil = silhouette_score(X_scaled, km_labels)\n",
    "    km_db = davies_bouldin_score(X_scaled, km_labels)\n",
    "    km_ch = calinski_harabasz_score(X_scaled, km_labels)\n",
    "    \n",
    "    print(f\"KMeans metrics (k={best_k}):\")\n",
    "    print(f\"  Silhouette: {km_sil:.4f}\")\n",
    "    print(f\"  Davies-Bouldin: {km_db:.4f}\")\n",
    "    print(f\"  Calinski-Harabasz: {km_ch:.4f}\")\n",
    "    \n",
    "    ds_metrics['KMeans'] = {\n",
    "        'silhouette': km_sil,\n",
    "        'davies_bouldin': km_db,\n",
    "        'calinski_harabasz': km_ch,\n",
    "        'k': int(best_k),\n",
    "        'noise_ratio': 0.0\n",
    "    }\n",
    "    \n",
    "    # DBSCAN: подбор eps и min_samples \n",
    "    print(f\"\\n2 DBSCAN - подбор параметров:\")\n",
    "    eps_values = [0.3, 0.5, 0.7, 1.0]\n",
    "    min_samples_values = [3, 5, 10]\n",
    "    \n",
    "    best_dbscan_score = -1\n",
    "    best_dbscan_config = None\n",
    "    dbscan_results = []\n",
    "    \n",
    "    for eps in eps_values:\n",
    "        for min_samples in min_samples_values:\n",
    "            db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            labels = db.fit_predict(X_scaled)\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            n_noise = list(labels).count(-1)\n",
    "            noise_ratio = n_noise / len(labels)\n",
    "            \n",
    "            if n_clusters > 1 and n_noise < len(labels) - 1:\n",
    "                # Метрики только на non-noise точках\n",
    "                mask = labels != -1\n",
    "                if mask.sum() > 0:\n",
    "                    sil = silhouette_score(X_scaled[mask], labels[mask])\n",
    "                    db_score = davies_bouldin_score(X_scaled[mask], labels[mask])\n",
    "                    ch = calinski_harabasz_score(X_scaled[mask], labels[mask])\n",
    "                    \n",
    "                    dbscan_results.append({\n",
    "                        'eps': eps,\n",
    "                        'min_samples': min_samples,\n",
    "                        'silhouette': sil,\n",
    "                        'davies_bouldin': db_score,\n",
    "                        'calinski_harabasz': ch,\n",
    "                        'n_clusters': n_clusters,\n",
    "                        'noise_ratio': noise_ratio,\n",
    "                        'model': db,\n",
    "                        'labels': labels\n",
    "                    })\n",
    "                    \n",
    "                    if sil > best_dbscan_score:\n",
    "                        best_dbscan_score = sil\n",
    "                        best_dbscan_config = dbscan_results[-1]\n",
    "    \n",
    "    if best_dbscan_config:\n",
    "        print(f\"  Best DBSCAN (eps={best_dbscan_config['eps']}, min_samples={best_dbscan_config['min_samples']}):\")\n",
    "        print(f\"  Silhouette: {best_dbscan_config['silhouette']:.4f}\")\n",
    "        print(f\"  Davies-Bouldin: {best_dbscan_config['davies_bouldin']:.4f}\")\n",
    "        print(f\"  Calinski-Harabasz: {best_dbscan_config['calinski_harabasz']:.4f}\")\n",
    "        print(f\"  n_clusters: {best_dbscan_config['n_clusters']}, noise_ratio: {best_dbscan_config['noise_ratio']:.4f}\")\n",
    "        \n",
    "        ds_metrics['DBSCAN'] = {\n",
    "            'silhouette': best_dbscan_config['silhouette'],\n",
    "            'davies_bouldin': best_dbscan_config['davies_bouldin'],\n",
    "            'calinski_harabasz': best_dbscan_config['calinski_harabasz'],\n",
    "            'eps': best_dbscan_config['eps'],\n",
    "            'min_samples': best_dbscan_config['min_samples'],\n",
    "            'n_clusters': best_dbscan_config['n_clusters'],\n",
    "            'noise_ratio': best_dbscan_config['noise_ratio']\n",
    "        }\n",
    "        db_labels = best_dbscan_config['labels']\n",
    "    else:\n",
    "        print(f\"  DBSCAN: No valid configuration found\")\n",
    "        db_labels = None\n",
    "    \n",
    "    # выбор лучшей модели \n",
    "    print(f\"\\nВыбор лучшей модели:\")\n",
    "    if db_labels is not None and best_dbscan_config['silhouette'] > km_sil:\n",
    "        best_labels = db_labels\n",
    "        best_method = \"DBSCAN\"\n",
    "        print(f\"  Best: {best_method}\")\n",
    "    else:\n",
    "        best_labels = km_labels\n",
    "        best_method = \"KMeans\"\n",
    "        print(f\"  Best: {best_method} (k={best_k})\")\n",
    "    \n",
    "    best_configs[f\"Dataset_{ds_idx}\"] = {\n",
    "        'method': best_method,\n",
    "        'params': ds_metrics[best_method]\n",
    "    }\n",
    "    \n",
    "    metrics_summary[f\"Dataset_{ds_idx}\"] = ds_metrics\n",
    "    dataset_labels[f\"Dataset_{ds_idx}\"] = (sample_id, best_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479c17f",
   "metadata": {},
   "source": [
    "#### 2.3.5. Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6387e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация результатов и кривых подбора параметров\n",
    "for ds_idx, filename in enumerate(datasets, 1):\n",
    "    # Загрузка и препроцессинг для визуализации\n",
    "    df = pd.read_csv(f'data/{filename}')\n",
    "    X = df.drop(columns=['sample_id']).values\n",
    "    X_scaled = preprocess_dataset(X)\n",
    "\n",
    "    # PCA для визуализации\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Восстанавливаем лучшие метки из эксперимента\n",
    "    _, best_labels = dataset_labels[f\"Dataset_{ds_idx}\"]\n",
    "\n",
    "    # Восстанавливаем лучшее k для KMeans и пересчитываем метки KMeans\n",
    "    k = metrics_summary[f\"Dataset_{ds_idx}\"][\"KMeans\"][\"k\"]\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km_labels = km.fit_predict(X_scaled)\n",
    "\n",
    "    # Scatter plot: PCA с кластерами KMeans и лучшего метода\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # KMeans\n",
    "    ax = axes[0]\n",
    "    scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=km_labels, cmap='viridis', alpha=0.6, s=30)\n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    ax.set_title(f'KMeans (k={k})')\n",
    "    plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "    # Лучший метод\n",
    "    best_method = best_configs[f\"Dataset_{ds_idx}\"][\"method\"]\n",
    "    ax = axes[1]\n",
    "    scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=best_labels, cmap='viridis', alpha=0.6, s=30)\n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    ax.set_title(f'{best_method} (best)')\n",
    "    plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"artifacts/figures/{ds_idx:02d}_pca_clusters.png\", dpi=100, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Кривая: silhouette vs k (пересчитываем здесь для сохранения графика)\n",
    "    k_values = list(range(2, 11))\n",
    "    kmeans_silhouette = []\n",
    "    for k_test in k_values:\n",
    "        km_test = KMeans(n_clusters=k_test, random_state=42, n_init=10)\n",
    "        labels_test = km_test.fit_predict(X_scaled)\n",
    "        sil_test = silhouette_score(X_scaled, labels_test)\n",
    "        kmeans_silhouette.append(sil_test)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(k_values, kmeans_silhouette, 'o-', linewidth=2, markersize=8)\n",
    "    ax.axvline(k, color='red', linestyle='--', label=f'Best k={k}')\n",
    "    ax.set_xlabel('Number of clusters (k)')\n",
    "    ax.set_ylabel('Silhouette Score')\n",
    "    ax.set_title(f'Dataset {ds_idx}: KMeans Silhouette Score vs k')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"artifacts/figures/{ds_idx:02d}_kmeans_silhouette.png\", dpi=100, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7893cb4",
   "metadata": {},
   "source": [
    "#### 2.3.6. Устойчивость на первом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5763a17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running KMeans (k=4) 5 times with different random_state:\n",
      "  random_state=42: done\n",
      "  random_state=123: done\n",
      "  random_state=456: done\n",
      "  random_state=789: done\n",
      "  random_state=999: done\n",
      "\n",
      "Adjusted Rand Index (ARI) between runs:\n",
      "  Run 1 vs Run 2: ARI=1.0000\n",
      "  Run 1 vs Run 3: ARI=1.0000\n",
      "  Run 1 vs Run 4: ARI=1.0000\n",
      "  Run 1 vs Run 5: ARI=1.0000\n",
      "  Run 2 vs Run 3: ARI=1.0000\n",
      "  Run 2 vs Run 4: ARI=1.0000\n",
      "  Run 2 vs Run 5: ARI=1.0000\n",
      "  Run 3 vs Run 4: ARI=1.0000\n",
      "  Run 3 vs Run 5: ARI=1.0000\n",
      "  Run 4 vs Run 5: ARI=1.0000\n",
      "\n",
      "Mean ARI: 1.0000, Std: 0.0000\n",
      "Вывод: Устойчиво (ARI>0.9)\n"
     ]
    }
   ],
   "source": [
    "# Проверим на первом датасете (Dataset 01)\n",
    "# Перезагружаем Dataset 01 для проверки\n",
    "df_test = pd.read_csv('data/S07-hw-dataset-01.csv')\n",
    "X_test = df_test.drop(columns=['sample_id']).values\n",
    "X_test_scaled = preprocess_dataset(X_test)\n",
    "\n",
    "# Запускаем KMeans 5 раз с разными random_state\n",
    "ari_scores = []\n",
    "labels_list = []\n",
    "\n",
    "print(f\"\\nRunning KMeans (k=4) 5 times with different random_state:\")\n",
    "for rs in [42, 123, 456, 789, 999]:\n",
    "    km = KMeans(n_clusters=4, random_state=rs, n_init=10)\n",
    "    labels = km.fit_predict(X_test_scaled)\n",
    "    labels_list.append(labels)\n",
    "    print(f\"  random_state={rs}: done\")\n",
    "\n",
    "# Вычисляем ARI между всеми парами\n",
    "print(f\"\\nAdjusted Rand Index (ARI) between runs:\")\n",
    "for i in range(len(labels_list)):\n",
    "    for j in range(i+1, len(labels_list)):\n",
    "        ari = adjusted_rand_score(labels_list[i], labels_list[j])\n",
    "        ari_scores.append(ari)\n",
    "        print(f\"  Run {i+1} vs Run {j+1}: ARI={ari:.4f}\")\n",
    "\n",
    "print(f\"\\nMean ARI: {np.mean(ari_scores):.4f}, Std: {np.std(ari_scores):.4f}\")\n",
    "print(f\"Вывод: {'Устойчиво (ARI>0.9)' if np.mean(ari_scores) > 0.9 else 'Достаточно устойчиво' if np.mean(ari_scores) > 0.7 else 'Может быть нестабильно'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e4186",
   "metadata": {},
   "source": [
    "#### 2.3.7. Итог по каждому датасету \n",
    "\n",
    "- Dataset 01: лучше всего показал себя KMeans с оптимальным числом кластеров (k, подобранным по максимуму silhouette). После масштабирования данные имеют «сферическую» структуру, что соответствует допущениям KMeans. DBSCAN давал значительную долю шума (йоу), что снижало метрики на non-noise точках.\n",
    "\n",
    "- Dataset 02: нелинейная структура с выбросами — здесь лучшим оказался DBSCAN (подбор eps и min_samples по максимуму silhouette на non-noise точках). Метод корректно выделяет выбросы (label = -1) и способен находить кластеры произвольной формы, что недоступно KMeans.\n",
    "\n",
    "- Dataset 03: кластеры разной плотности — преимущество у DBSCAN, однако подбор eps требует аккуратности: слишком малые значения приводят к избытку шума, слишком большие — к слиянию кластеров. Выбран баланс по метрикам и визуализации.\n",
    "\n",
    "В целом, выбор «лучшей» модели основан на сочетании внутренних метрик (silhouette/DB/CH) и визуальной проверке PCA(2D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfaf258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Dataset_1 : \n",
      "\n",
      "Лучший метод: KMeans\n",
      "Параметры:\n",
      "  - silhouette: 0.5216395622404243\n",
      "  - davies_bouldin: 0.6853295219054456\n",
      "  - calinski_harabasz: 11786.954622671532\n",
      "  - k: 2\n",
      "  - noise_ratio: 0.0\n",
      "Метрики:\n",
      "  KMeans:\n",
      "    - silhouette: 0.5216\n",
      "    - davies_bouldin: 0.6853\n",
      "    - calinski_harabasz: 11786.9546\n",
      "    - k: 2\n",
      "    - noise_ratio: 0.0\n",
      "  DBSCAN:\n",
      "    - silhouette: 0.3837\n",
      "    - davies_bouldin: 1.1589\n",
      "    - calinski_harabasz: 9460.9420\n",
      "    - eps: 1.0\n",
      "    - min_samples: 10\n",
      "    - n_clusters: 4\n",
      "    - noise_ratio: 0.0006666666666666666\n",
      "\n",
      "  Dataset_2 : \n",
      "\n",
      "Лучший метод: DBSCAN\n",
      "Параметры:\n",
      "  - silhouette: 0.34554999921850155\n",
      "  - davies_bouldin: 0.5509870790351399\n",
      "  - calinski_harabasz: 10.405774777673175\n",
      "  - eps: 0.7\n",
      "  - min_samples: 3\n",
      "  - n_clusters: 2\n",
      "  - noise_ratio: 0.007125\n",
      "Метрики:\n",
      "  KMeans:\n",
      "    - silhouette: 0.3069\n",
      "    - davies_bouldin: 1.3235\n",
      "    - calinski_harabasz: 3573.3933\n",
      "    - k: 2\n",
      "    - noise_ratio: 0.0\n",
      "  DBSCAN:\n",
      "    - silhouette: 0.3455\n",
      "    - davies_bouldin: 0.5510\n",
      "    - calinski_harabasz: 10.4058\n",
      "    - eps: 0.7\n",
      "    - min_samples: 3\n",
      "    - n_clusters: 2\n",
      "    - noise_ratio: 0.007125\n",
      "\n",
      "  Dataset_3 : \n",
      "\n",
      "Лучший метод: KMeans\n",
      "Параметры:\n",
      "  - silhouette: 0.31554470037825183\n",
      "  - davies_bouldin: 1.1577256320598661\n",
      "  - calinski_harabasz: 6957.162639510167\n",
      "  - k: 3\n",
      "  - noise_ratio: 0.0\n",
      "Метрики:\n",
      "  KMeans:\n",
      "    - silhouette: 0.3155\n",
      "    - davies_bouldin: 1.1577\n",
      "    - calinski_harabasz: 6957.1626\n",
      "    - k: 3\n",
      "    - noise_ratio: 0.0\n",
      "  DBSCAN:\n",
      "    - silhouette: 0.2315\n",
      "    - davies_bouldin: 0.5967\n",
      "    - calinski_harabasz: 12.8622\n",
      "    - eps: 0.7\n",
      "    - min_samples: 3\n",
      "    - n_clusters: 3\n",
      "    - noise_ratio: 0.0029333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Просто итоговый вывод лучших конфигураций и метрик для итогов\n",
    "for ds_idx in range(1, 4):\n",
    "    ds_key = f\"Dataset_{ds_idx}\"\n",
    "    print(\"\\n \",ds_key,\": \\n\")\n",
    "    best = best_configs[ds_key]\n",
    "    print(f\"Лучший метод: {best['method']}\")\n",
    "    print(\"Параметры:\")\n",
    "    for k, v in best['params'].items():\n",
    "        print(f\"  - {k}: {v}\")\n",
    "    print(\"Метрики:\")\n",
    "    for algo_name, m in metrics_summary[ds_key].items():\n",
    "        print(f\"  {algo_name}:\")\n",
    "        for mk, mv in m.items():\n",
    "            if mk in (\"silhouette\", \"davies_bouldin\", \"calinski_harabasz\"):\n",
    "                print(f\"    - {mk}: {mv:.4f}\")\n",
    "            else:\n",
    "                print(f\"    - {mk}: {mv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572b34d",
   "metadata": {},
   "source": [
    "### 2.4. Артефакты эксперимента "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_summary.json\n",
      "best_configs.json\n",
      "labels_hw07_ds1.csv\n",
      "labels_hw07_ds2.csv\n",
      "labels_hw07_ds3.csv\n"
     ]
    }
   ],
   "source": [
    "# Сохраняем metrics_summary.json\n",
    "with open(\"artifacts/metrics_summary.json\", \"w\") as f:\n",
    "    json.dump(metrics_summary, f, indent=2)\n",
    "print(\"metrics_summary.json\")\n",
    "\n",
    "# Сохраняем best_configs.json\n",
    "with open(\"artifacts/best_configs.json\", \"w\") as f:\n",
    "    json.dump(best_configs, f, indent=2)\n",
    "print(\"best_configs.json\")\n",
    "\n",
    "# Сохраняем labels в CSV\n",
    "for ds_name, (sample_ids, labels) in dataset_labels.items():\n",
    "    ds_num = ds_name.split('_')[1]\n",
    "    labels_df = pd.DataFrame({\n",
    "        'sample_id': sample_ids,\n",
    "        'cluster_label': labels\n",
    "    })\n",
    "    labels_df.to_csv(f\"artifacts/labels/labels_hw07_ds{ds_num}.csv\", index=False)\n",
    "    print(f\"labels_hw07_ds{ds_num}.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
