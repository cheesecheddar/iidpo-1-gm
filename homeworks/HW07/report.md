# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): S07-hw-dataset-01.csv, S07-hw-dataset-02.csv, S07-hw-dataset-03.csv.

### 1.1 Dataset A

- Файл: `homeworks/HW07/data/S07-hw-dataset-01.csv`
- Размер: (12001, 9)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные шкалы признаков, наличие сильных координатных направлений (f02, f04), возможные выбросы.

### 1.2 Dataset B

- Файл: `homeworks/HW07/data/S07-hw-dataset-02.csv`
- Размер: (8001, 4)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: два плотных кластера с шумовой координатой (`z_noise`), различная плотность.

### 1.3 Dataset C

- Файл: `homeworks/HW07/data/S07-hw-dataset-03.csv`
- Размер: (15001, 5)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: коррелированные признаки (`f_corr`), добавлен шумовой признак (`f_noise`), кластеры умеренно разделены.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: имputation (среднее) + стандартное масштабирование (StandardScaler); PCA(2D) только для визуализации.
- Поиск гиперпараметров:
  - KMeans: `k = {2..10}`, фиксировали `random_state=42`, `n_init=10`.
  - DBSCAN: `eps = {0.3..1.5}` (шаг 0.1), `min_samples = {3..10}`.
  - Критерий выбора: максимальный silhouette; при близких значениях учитывали меньший Davies-Bouldin и разумный Calinski-Harabasz.
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz. Для DBSCAN метрики считались на точках без шума и дополнительно фиксировали долю шума.
- Визуализация: PCA(2D) scatter для лучших конфигураций + график silhouette vs k для KMeans. Фигуры сохранены: `homeworks/HW07/artifacts/figures/`.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans: подбор количества кластеров `k = {2..10}`, `random_state=42`, `n_init=10`.
- DBSCAN: подбор `eps = {0.3..1.5}` и `min_samples = {3..10}`; анализ доли шума.

Опционально: AgglomerativeClustering не использовался.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans (`k=2`).
- Метрики (silhouette / DB / CH): 0.522 / 0.685 / 11786.95.
- Если был DBSCAN: доля шума ≈ 0.00067; метрики хуже (silhouette ≈ 0.384).
- Коротко: KMeans хорошо разделяет два компактных кластера при стандартизации; DBSCAN почти не отсеивает шум, но теряет качество из-за глобальной структуры.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN (`eps=0.7`, `min_samples=3`, `n_clusters=2`).
- Метрики (silhouette / DB / CH): 0.346 / 0.551 / 10.41.
- Если был DBSCAN: доля шума ≈ 0.0071 (разумная). KMeans в этом датасете уступает (silhouette ≈ 0.307), вероятно из-за различной плотности и шумовой координаты.
- Коротко: DBSCAN лучше ловит разную плотность и устойчив к шуму по `z_noise`, формируя два естественных кластера.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans (`k=3`).
- Метрики (silhouette / DB / CH): 0.316 / 1.158 / 6957.16.
- Если был DBSCAN: доля шума ≈ 0.00293; метрики хуже (silhouette ≈ 0.232).
- Коротко: при умеренно разделённых кластерах и коррелированных признаках KMeans с масштабированием даёт более стабильные группы.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему? На данных с неоднородной плотностью и вытянутыми формами; требует равных дисперсий и сферических кластеров.
- Где DBSCAN выигрывает и почему? На данных с естественными плотностями (Dataset B): устойчив к шуму, не требует заранее знать `k`.
- Что сильнее всего влияло на результат? Масштабирование и наличие шумовых/коррелированных признаков; без стандартизации silhouette заметно хуже, шумовые координаты сбивают KMeans.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: 5 запусков KMeans (`k=4`) на Dataset A с разными `random_state`.
- Результат: ARI между всеми парами запусков ≈ 1.000 (mean=1.000, std=0.000).
- Вывод: устойчиво (ARI>0.9). Итерации сходятся к одному разбиению благодаря чёткой структуре и стандартизации.

### 5.3 Интерпретация кластеров

- Интерпретация: по профилям признаков (средние/медианы) и PCA-проекциям на 2D; в Dataset A разбиение объясняется направлениями `f02`/`f04`, в Dataset B — двумя плотными группами по `(x1,x2)` с шумом в `z_noise`, в Dataset C — умеренно разделённые группы с влиянием `f_corr`.
- Выводы: признаки с крупным масштабом и шумовые координаты требуют стандартизации и/или методов, устойчивых к шуму; визуализация PCA помогает объяснять разбиения.

## 6. Conclusion

- Стандартизация критична: без неё метрики падают и KMeans деградирует.
- Silhouette — удобный первичный критерий, но полезно учитывать Davies-Bouldin/Calinski-Harabasz.
- DBSCAN подходит для данных с неоднородной плотностью и шумом (Dataset B).
- KMeans предпочтителен на компактных, сферических кластерах (Datasets A, C).
- Устойчивость нужно проверять: ARI между запусками подтверждает надёжность результата.
- PCA-визуализации помогают интерпретировать кластеры, но не заменяют метрики.
